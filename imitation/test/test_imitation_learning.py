from __future__ import unicode_literals
from glob import glob
import os
import shutil

import cv2
import numpy as np
from PIL import Image as PImage
import tensorflow as tf

import constants as ilc
import trainer
import preprocessor


SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))


LOCAL_H5_IL_DATA_DIR = os.path.join(SCRIPT_DIR, 'mock_data_181018/imitation_learning/h5_files/AgentHuman')
LOCAL_PREPROC_DATA_DIR = '/data/imitation_learning/preprocessed_test'
LOCAL_TRAINING_DATA_DIR = '/data/imitation_learning/train_test'


def clean_up_test_dirs():
    try:
        shutil.rmtree(LOCAL_PREPROC_DATA_DIR)
    except OSError:
        pass
    try:
        shutil.rmtree(LOCAL_TRAINING_DATA_DIR)
    except OSError:
        pass


def setup_module():
    clean_up_test_dirs()


def teardown_module():
    clean_up_test_dirs()


def run_preprocessing():
    if not os.path.exists(preprocessor.FLAGS.preproc_output_dir):
        os.makedirs(preprocessor.FLAGS.preproc_output_dir )

    preprocessor.run_pipeline()

    # Test if tfrecords are written
    for split in [preprocessor.VAL_SPLIT, preprocessor.TRAIN_SPLIT]:
        tfrecord_files = glob(os.path.join(preprocessor.FLAGS.preproc_output_dir, '{}*.tfrecord.gz'.format(split)))
        assert len(tfrecord_files) > 0, 'Found no {} tfrecords'.format(split)


def run_trainer():
    trainer.main()
    assert len(glob(os.path.join(trainer.FLAGS.output_dir, '*ckpt*'))) > 0, 'Model did not checkpoint'


class Image(object):
    """Data generated by a Camera."""

    def __init__(self, width, height, image_type, raw_data, data):
        assert len(raw_data) == 4 * width * height
        self.width = width
        self.height = height
        self.type = image_type
        self.raw_data = raw_data
        self.data = data


def prepare_image():
    """Loads local image and returns it.

    Returns:
        np.array
    """
    arbitrary_image_file = '/imitation/test/rviz_carla_default.png'
    rgb = np.asarray(PImage.open(arbitrary_image_file))
    return rgb


def _convert_to_input_fn(img, current_speed, image_cut=(115, 510), desired_shape=(ilc.IMG_HEIGHT, ilc.IMG_WIDTH, 3)):
    # Crop image
    img = img[image_cut[0]:image_cut[1], :]

    # Scale image
    if img.shape != desired_shape:
        # NOTE: cv2.resize expects a counter-intuitive order of arguments: (num_columns, num_rows).
        img = cv2.resize(img, (ilc.IMG_WIDTH, ilc.IMG_HEIGHT))
    assert img.shape == desired_shape, \
        'image shape is {} but should be {}'.format(str(img.shape), str(desired_shape))

    # Normalize image
    image_normalized = (img / 255.0).astype(np.float32)

    # Check speed
    assert current_speed.shape == (1,), \
        'Expected current_speed to be singleton array. Instead found {}'.format(current_speed)

    predict_input_fn = tf.estimator.inputs.numpy_input_fn(
       x={
           ilc.FEATKEY_IMG: np.expand_dims(image_normalized, axis=0),
           ilc.TGT_SPEED: current_speed.astype(np.float32),
       },
       num_epochs=1,
       shuffle=False)

    return predict_input_fn


def run_predict():
    image = prepare_image()
    input_fn = _convert_to_input_fn(image, current_speed=np.array([5.]))

    estimator = trainer.ImitationLearningTrainer().estimator
    prediction = next(estimator.predict(input_fn))

    assert prediction['Branches'].shape == (4, 3)
    assert prediction['Speed_Branch'].shape == ()


def test_integration(request):
    preprocessor.FLAGS.data_dir = LOCAL_H5_IL_DATA_DIR
    preprocessor.FLAGS.preproc_output_dir = LOCAL_PREPROC_DATA_DIR
    preprocessor.FLAGS.h5_files_per_split = 2
    run_preprocessing()

    trainer.FLAGS.train_path = os.path.join(LOCAL_PREPROC_DATA_DIR, 'TRAIN*.tfrecord.gz')
    trainer.FLAGS.validation_path = os.path.join(LOCAL_PREPROC_DATA_DIR, 'VAL*.tfrecord.gz')
    trainer.FLAGS.train_steps = 5
    trainer.FLAGS.output_dir = LOCAL_TRAINING_DATA_DIR
    run_trainer()

    run_predict()
